{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c336b8-15ad-40b6-99a2-9e86c338b42c",
   "metadata": {},
   "source": [
    "# [Optional] Run the image classifier on inputs from webcam/ JS canvas (in realtime)  \n",
    "\n",
    "This is an optional notebook for this week, run this only if you're interested in it.\n",
    "\n",
    "This notebook allows you to use real-time data from webcam or Javascript canvas as inputs for the image classifier that we trained in the `02_image_classifier_pytorch.ipynb`  \n",
    "\n",
    "\n",
    "We will useÂ a Python library called [Flask](https://flask.palletsprojects.com/en/3.0.x/). It allows you to create web applications in your local Python environment. The advantage of using Flask is that you can build web interfaces for your Python programs and use Javascript to process media inputs such as webcam, audio, or JS painting canvas. \n",
    "\n",
    "\n",
    "READ BEFORE PROCEEDING:\n",
    "\n",
    "1. This notebook only works if it's running on your local machine, this means - **it doesn't work on Google Colab** or other cloud platforms.  \n",
    "   It also doesn't work if you're remotely connecting to devices in CCI.  \n",
    "2. As we mentioned in the first lecture, Python is not good at processing real-time data. So, this approach is definately not the best practice, but it's good enough for prototype and demonstration purposes - use it with caution.\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281203e-94d4-43f3-aa2e-6413912ab045",
   "metadata": {},
   "source": [
    "## Step 0 - Download and installation (do this only once)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f790a7-c70b-4064-9f1c-f7f1eb944f0f",
   "metadata": {},
   "source": [
    "This is a GitHub repository for real-time bi-directional communication between Python server and front-end client.  \n",
    "Created by Jasper https://github.com/jasper-zheng/realtime-flask-notebook , feel free to reuse it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d9f7c2-a42a-4281-a8d9-35756413b355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'realtime-flask-notebook'...\n",
      "remote: Enumerating objects: 46, done.\u001b[K\n",
      "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 46 (delta 11), reused 41 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (46/46), 168.08 KiB | 3.65 MiB/s, done.\n",
      "Resolving deltas: 100% (11/11), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jasper-zheng/realtime-flask-notebook.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6695a56f-4436-4c3a-aacf-cc826ad4ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting Flask-SocketIO\n",
      "  Downloading Flask_SocketIO-5.5.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting Werkzeug\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/coding3/lib/python3.12/site-packages (from flask) (3.1.6)\n",
      "Collecting itsdangerous>=2.2 (from flask)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/homebrew/Caskroom/miniforge/base/envs/coding3/lib/python3.12/site-packages (from flask) (8.1.8)\n",
      "Collecting blinker>=1.9 (from flask)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting python-socketio>=5.12.0 (from Flask-SocketIO)\n",
      "  Downloading python_socketio-5.13.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/coding3/lib/python3.12/site-packages (from Werkzeug) (3.0.2)\n",
      "Collecting bidict>=0.21.0 (from python-socketio>=5.12.0->Flask-SocketIO)\n",
      "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting python-engineio>=4.11.0 (from python-socketio>=5.12.0->Flask-SocketIO)\n",
      "  Downloading python_engineio-4.12.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.11.0->python-socketio>=5.12.0->Flask-SocketIO)\n",
      "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->Flask-SocketIO)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/homebrew/Caskroom/miniforge/base/envs/coding3/lib/python3.12/site-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio>=5.12.0->Flask-SocketIO) (0.14.0)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Downloading Flask_SocketIO-5.5.1-py3-none-any.whl (18 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading python_socketio-5.13.0-py3-none-any.whl (77 kB)\n",
      "Downloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
      "Downloading python_engineio-4.12.0-py3-none-any.whl (59 kB)\n",
      "Downloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, Werkzeug, itsdangerous, blinker, bidict, simple-websocket, flask, python-engineio, python-socketio, Flask-SocketIO\n",
      "Successfully installed Flask-SocketIO-5.5.1 Werkzeug-3.1.3 bidict-0.23.1 blinker-1.9.0 flask-3.1.0 itsdangerous-2.2.0 python-engineio-4.12.0 python-socketio-5.13.0 simple-websocket-1.1.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flask Flask-SocketIO Werkzeug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720252eb-e3d0-499c-897f-00e43b02b1e8",
   "metadata": {},
   "source": [
    "## Step 1 - Load the trained model  \n",
    "\n",
    "Make sure you have finished the `02_image_classifier_pytorch.ipynb` notebook, and have the trained model saved as `model_final.pt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64c321-d2f6-4da1-90ab-0d832e580fbc",
   "metadata": {},
   "source": [
    "Again, before we start, let's config the device PyTorch is using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea1ea82-0e11-4e7c-b29f-defc6fdb81a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ee0eed-f424-40bc-87bf-cf36b1e497de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import ConvNeuralNetwork\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bc2b6-2a1d-4793-9ece-2783bb348d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_channel = _______ # number of colour channels of inputs (img_channel = 1 for greyscale, img_channel = 3 for RGB).\n",
    "img_resolution = _______ # width and height of input images, this should match the model you trained (e.g. img_resolution = 64 for 64x64 inputs)\n",
    "num_classes = _______ # how many categories the model is classifying (e.g. num_classes = 3 for 3 classes)\n",
    "\n",
    "# make sure the parameters are the same as when the model is created\n",
    "model = ConvNeuralNetwork(img_channel = img_channel, \n",
    "                          img_resolution = img_resolution,\n",
    "                          num_classes = num_classes)\n",
    "\n",
    "# load the saved model, make sure the path is correct\n",
    "model.load_state_dict(torch.load('model_final.pt'))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9dad61-ff2a-4911-9eb2-2496feb93148",
   "metadata": {},
   "source": [
    "## Step 2 - Set up the web application  \n",
    "\n",
    "Config the web application using [Flask](https://flask.palletsprojects.com/en/3.0.x/api/) and [Socket.IO](https://socket.io/docs/v4/).  \n",
    "We can skip over some technical details of how this works, but as an overview, they're going to help us set up a **server** that runs our classifier model, and a **client** that runs the Javascript interface. The client sends a frame of input image to the server, the server uses the classifier model to predict a class, and sends the prediction back to the client.\n",
    "\n",
    "<img src=\"./src/graphics/client_server.jpg\" width=\"600px\"></img>  \n",
    "\n",
    "First, let's import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0e866-d614-465d-8f7e-1fdcf99ec81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "base_dir = 'realtime-flask-notebook'\n",
    "sys.path.append(f'{base_dir}')\n",
    "\n",
    "from FlaskProcessor import Processor\n",
    "\n",
    "import os, sys\n",
    "import logging\n",
    "\n",
    "from flask import Flask, render_template\n",
    "from flask_socketio import SocketIO, emit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3675245-c484-494d-836b-0b9e02065521",
   "metadata": {},
   "source": [
    "Then, config the base directory that the web app is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a27c48e0-156c-4905-83a9-b99f61a43084",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_dir = os.path.abspath(f'{base_dir}/templates')\n",
    "static_dir = os.path.abspath(f'{base_dir}/static')\n",
    "\n",
    "app = Flask(__name__, static_folder=static_dir, template_folder=template_dir)\n",
    "socketio = SocketIO(app)\n",
    "processor = Processor(model, device = device, colour_channels = img_channel, img_resolution = img_resolution)\n",
    "\n",
    "@socketio.on('packet_from_js', namespace='/demo')\n",
    "def packet_from_js(packet_from_js):\n",
    "    img = packet_from_js.split(\",\")[1]\n",
    "    processor.enqueue_input(img)\n",
    "    class_idx = processor.get_frame()\n",
    "    emit('packet_from_py', {'class_name': class_idx}, namespace='/demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bca498-ee01-4c64-b832-80aa38830433",
   "metadata": {},
   "source": [
    "## Step 3 - Activate the web app and go to its URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d64cb42-cdf8-45b8-ba00-38259fd70613",
   "metadata": {},
   "source": [
    "**Follow option 1 or option 2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c448507-b9cb-4b1c-bed0-c403a961d423",
   "metadata": {},
   "source": [
    "### Option 1: Inputs from Webcam  \n",
    "\n",
    "If you chose to train the Pinterest image classifier, you might want to go with this option, it will use your webcam as input for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f38287-873a-4051-be65-2deaa74e5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('webcam.html')\n",
    "\n",
    "# enter the names of cateories you have\n",
    "processor.set_class_name(['_____', '_____', '_____', .....])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3955710-9c33-4a1c-9c9b-37a54d0a300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 5005\n",
    "print(f'open your browser and go to http://127.0.0.1:{port}/ \\n')\n",
    "\n",
    "socketio.run(app, port=port, allow_unsafe_werkzeug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae115f6-55d3-45f1-924c-0fa365d1ba4a",
   "metadata": {},
   "source": [
    "### Option 2: Sketch via mouse  \n",
    "\n",
    "If you chose to train the sketch classifier, you might want to go with this option, it will open a Javascript canvas where you can use your mouse to draw sketches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eab042-1557-4f36-8fa9-d94850e2b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('sketch.html')\n",
    "\n",
    "# enter the names of cateories you have\n",
    "processor.set_class_name(['apple', 'basketball', 'book', 'cat', 'duck', 'fish', 'flower', 'mouth', 'mushroom', 'whale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e42c4-090e-44d8-983f-74f103880895",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 5005\n",
    "print(f'open your browser and go to http://127.0.0.1:{port}/ \\n')\n",
    "\n",
    "socketio.run(app, port=port, allow_unsafe_werkzeug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
