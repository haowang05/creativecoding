{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7ac306",
   "metadata": {},
   "source": [
    "\n",
    "## åˆ›å»ºæ–°çš„pyç¯å¢ƒ\n",
    "Create Environment\n",
    "`conda create -n myvoiceenv python=3.10`\n",
    "\n",
    "Activate Environment\n",
    "`conda activate myvoiceenv`\n",
    "\n",
    "Install Dependencies\n",
    "`pip install vosk`\n",
    "\n",
    "`pip install sounddevice`\n",
    "\n",
    "`pip install pyautogui`\n",
    "\n",
    "For the pyaudio library`\n",
    "\n",
    "`brew install portaudio`\n",
    "\n",
    "`pip install pyaudio`\n",
    "\n",
    "å¦‚æœæ²¡æœ‰ brewï¼Œè¿è¡Œ â¬‡ï¸\n",
    "\n",
    "`/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"`\n",
    "\n",
    "---\n",
    "æ¨¡å‹ä¸‹è½½ https://alphacephei.com/vosk/models\n",
    "\n",
    "* æœ¬é¡¹ç›®ä½¿ç”¨çš„æ˜¯ vosk-model-small-en-us-0.15ï¼Œä¸‹è½½åæ”¾åœ¨ipynbæ–‡ä»¶åŒçº§ç›®å½•ä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d739ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 MacBook Airéº¦å…‹é£, Core Audio (1 in, 0 out)\n",
      "  1 MacBook Airæ‰¬å£°å™¨, Core Audio (0 in, 2 out)\n",
      "  2 makou Microphone, Core Audio (1 in, 0 out)\n",
      "> 3 ğŸ¸, Core Audio (1 in, 0 out)\n",
      "< 4 ğŸ¸, Core Audio (0 in, 2 out)\n",
      "  5 Microsoft Teams Audio, Core Audio (1 in, 1 out)\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "print(sd.query_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2607e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70231c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from vosk-model-small-en-us-0.15/graph/HCLr.fst vosk-model-small-en-us-0.15/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo vosk-model-small-en-us-0.15/graph/phones/word_boundary.int\n",
      "Exception ignored in: <function KaldiRecognizer.__del__ at 0x1073c91b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/myvoiceenv/lib/python3.10/site-packages/vosk/__init__.py\", line 161, in __del__\n",
      "    _c.vosk_recognizer_free(self._handle)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ Listening...\n",
      "[PARTIAL] the\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odds with ha\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it will ah i'll do what you're gonna\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it will ah i'll do what you're gonna die but\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it will ah i'll do what you're gonna die but i\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it will ah i'll do what you're gonna die but ah follow you need to read or what you guys i\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it will ah i'll do what you're gonna die but ah follow you need to read or what you go tell you what you got\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it will ah i'll do what you're gonna die but ah follow you need to read or what you go tell you what you got to\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it will ah i'll do what you're gonna die but ah follow you need to read or what you go tell you what you got turns you should be a y la\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it will ah i'll do what you're gonna die but ah follow you need to read or what you go tell you what you got turns you should be a y la tarde other\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it will ah i'll do what you're gonna die but ah follow you need to read or what you go tell you what you got turns you should be a y la tarde other she didn't have\n",
      "[PARTIAL] the for evil what's it to trigger can comfortably on them vertical atlanta ga ga the double life at a low the nicer than do with how odd it will ah i'll do what you're gonna die but ah follow you need to read or what you go tell you what you got turns you should be a y la tarde other she didn't have a faggot unity\n",
      "â¬†ï¸ Release [space]\n",
      "[PARTIAL] natural\n",
      "[FULL TEXT] natural\n",
      "[PARTIAL] oh\n",
      "â¬†ï¸ Release [space]\n",
      "[PARTIAL] tumblr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# ä¸»çº¿ç¨‹æŒ‚èµ·å³å¯\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 111\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39mrecognizer_loop, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import sounddevice as sd\n",
    "import queue\n",
    "import json\n",
    "import pyautogui\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# === é…ç½®å‚æ•° ===\n",
    "MODEL_PATH = \"vosk-model-small-en-us-0.15\"\n",
    "SAMPLE_RATE = 16000\n",
    "BLOCK_SIZE = 8000\n",
    "COOLDOWN = 0.05  # ç§’\n",
    "\n",
    "# === å…³é”®è¯é…ç½® ===\n",
    "instant_groups = {\n",
    "    \"w\": [\"up\", \"op\"],\n",
    "    \"a\": [\"left\", \"æš‚åœä¸€ä¸‹\", \"zantie\", \"zanting\"],\n",
    "    \"s\": [\"down\", \"done\", \"don't\", \"don\", \"damn\"],\n",
    "    \"d\": [\"right\", \"tingzhi\", \"åœä¸‹\"],\n",
    "    \"p\": [\"light\", \"like\", \"night\"]\n",
    "}\n",
    "\n",
    "hold_groups = {\n",
    "    \"space\": [\"a\", \"ah\", \"eh\", \"hey\"]\n",
    "}\n",
    "\n",
    "# === çŠ¶æ€å˜é‡ ===\n",
    "q_audio = queue.Queue()\n",
    "last_trigger_time = {k: 0 for k in instant_groups}\n",
    "hold_key_status = {k: False for k in hold_groups}\n",
    "\n",
    "# === éŸ³é¢‘è¾“å…¥å›è°ƒ ===\n",
    "def audio_callback(indata, frames, time_info, status):\n",
    "    if status:\n",
    "        print(\"âš ï¸\", status)\n",
    "    q_audio.put(bytes(indata), block=False)\n",
    "\n",
    "# === åˆå§‹åŒ–æ¨¡å‹ ===\n",
    "model = Model(MODEL_PATH)\n",
    "recognizer = KaldiRecognizer(model, SAMPLE_RATE)\n",
    "\n",
    "# === å¿«é€Ÿåˆ¤æ–­å‡½æ•° ===\n",
    "def fuzzy_match(text, keywords):\n",
    "    text = text.lower()\n",
    "    return any(word in text for word in keywords)\n",
    "\n",
    "# === å®æ—¶è¯­éŸ³å¤„ç†çº¿ç¨‹ ===\n",
    "def recognizer_loop():\n",
    "    print(\"ğŸ§ Listening...\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            data = q_audio.get_nowait()\n",
    "        except queue.Empty:\n",
    "            time.sleep(0.001)\n",
    "            continue\n",
    "\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            text = result.get(\"text\", \"\").lower()\n",
    "\n",
    "            if text:\n",
    "                # ğŸ è°ƒè¯•è¾“å‡ºï¼šå®Œæ•´è¯†åˆ«\n",
    "                print(f\"[FULL TEXT] {text}\")  # â†â†â†â† å¯åœ¨è°ƒè¯•å®Œæˆåæ³¨é‡Š\n",
    "\n",
    "                # ç¬æ—¶å…³é”®è¯åŒ¹é…\n",
    "                for key, keywords in instant_groups.items():\n",
    "                    now = time.time()\n",
    "                    if fuzzy_match(text, keywords) and (now - last_trigger_time[key] > COOLDOWN):\n",
    "                        pyautogui.press(key)\n",
    "                        last_trigger_time[key] = now\n",
    "                        print(f\"ğŸ”˜ {text} -> press [{key}]\")\n",
    "\n",
    "        else:\n",
    "            partial = json.loads(recognizer.PartialResult())\n",
    "            partial_text = partial.get(\"partial\", \"\").lower()\n",
    "\n",
    "            if partial_text:\n",
    "                # ğŸ è°ƒè¯•è¾“å‡ºï¼šéƒ¨åˆ†è¯†åˆ«\n",
    "                print(f\"[PARTIAL] {partial_text}\")  # â†â†â†â† å¯åœ¨è°ƒè¯•å®Œæˆåæ³¨é‡Š\n",
    "\n",
    "            # æŒç»­å…³é”®è¯åŒ¹é…\n",
    "            for key, keywords in hold_groups.items():\n",
    "                if fuzzy_match(partial_text, keywords):\n",
    "                    if not hold_key_status[key]:\n",
    "                        pyautogui.keyDown(key)\n",
    "                        hold_key_status[key] = True\n",
    "                        print(f\"â¬‡ï¸ Hold [{key}]\")\n",
    "                else:\n",
    "                    if hold_key_status[key]:\n",
    "                        pyautogui.keyUp(key)\n",
    "                        hold_key_status[key] = False\n",
    "                        print(f\"â¬†ï¸ Release [{key}]\")\n",
    "\n",
    "\n",
    "# === å¯åŠ¨éŸ³é¢‘å’Œè¯†åˆ«çº¿ç¨‹ ===\n",
    "def main():\n",
    "    stream = sd.RawInputStream(\n",
    "        samplerate=SAMPLE_RATE,\n",
    "        blocksize=BLOCK_SIZE,\n",
    "        dtype='int16',\n",
    "        channels=1,\n",
    "        callback=audio_callback,\n",
    "        device=0  # ä¸¾ä¾‹ï¼Œä½ çš„éº¦å…‹é£è®¾å¤‡ç¼–å·\n",
    "    )\n",
    "\n",
    "    with stream:\n",
    "        threading.Thread(target=recognizer_loop, daemon=True).start()\n",
    "        while True:\n",
    "            time.sleep(1)  # ä¸»çº¿ç¨‹æŒ‚èµ·å³å¯\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvoiceenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
