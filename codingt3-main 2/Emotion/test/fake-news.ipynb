{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45766610",
   "metadata": {},
   "source": [
    "## 创建新的py环境\n",
    "\n",
    "Activate Environment\n",
    "\n",
    "`conda activate myvoiceenv`\n",
    "\n",
    "Install Dependencies\n",
    "\n",
    "`pip install transformers torch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb331bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# load model\n",
    "model_name = \"sshleifer/tiny-gpt2\" \n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def generate_fake_news_local(emotion):\n",
    "    emotion_to_prompt = {\n",
    "        \"sad\": \"Fake news that is happy.  \",\n",
    "        \"angry\": \"Fake news that is calming. \",\n",
    "        \"fear\": \"Fake news that makes people feel safe.\",\n",
    "        \"disgust\": \"Funny fake news. \",\n",
    "        \"happy\": \"Crazy fun fake news. \",\n",
    "        \"neutral\": \"Ironic fake news headline. \",\n",
    "        \"surprise\": \"Magical fake news.  \"\n",
    "    }\n",
    "    \n",
    "    prompt = emotion_to_prompt.get(emotion, \"Fake news: \")\n",
    "    \n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=30,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=1.1,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "    \n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # ouput\n",
    "    return output_text.replace(prompt, \"\").strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f99bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected emotion: sad\n",
      "Generated fake news headline: 653 BooneGy Dreams Late Pocket boils bravery Bend deflect membershipMostshowsMini workshopsaciousGyMostSexual653 Tre rubbing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emotion = \"sad\"  \n",
    "headline = generate_fake_news_local(emotion)\n",
    "\n",
    "print(f\"Detected emotion: {emotion}\")\n",
    "print(f\"Generated fake news headline: {headline}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37adc40",
   "metadata": {},
   "source": [
    "## Local Language Models -> Large Language Models via API\n",
    "Initially, I attempted to generate fake news titles by directly feeding prompts into local language models. However, the generated outputs often had little to no relation to the given prompts.\n",
    "\n",
    "I tested several versions of GPT-2:\n",
    "\n",
    "* Both gpt2 and distilgpt2 frequently crashed during output with the error: Disposing session as kernel process died ExitCode.\n",
    "\n",
    "* Only sshleifer/tiny-gpt2 could run without crashing, but its outputs were irrelevant to the prompts and lacked coherence.\n",
    "\n",
    "Given these issues, I decided to switch to using large language models via API, since running them locally was not feasible due to their size.\n",
    "\n",
    "However, this approach introduced new problems:\n",
    "\n",
    "* The generation speed via API was extremely slow.\n",
    "\n",
    "* If the timeout value was set too low, it would result in errors; if set too high, the waiting time became impractical for real-time use.\n",
    "\n",
    "* The generated titles were often too realistic, making it hard for users to immediately recognize them as fake news, which undermined the satirical or critical purpose of the project.\n",
    "\n",
    "I conducted several tests using the Qwen/QwQ-32B model, primarily by adjusting the prompt and generation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82eeb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emotion: sad\n",
      "[API Error]: HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=10)\n",
      "Fake News: [Failed to generate fake news]\n",
      "\n",
      "Emotion: angry\n",
      "Fake News: Certainly! Below is **fictional and satirical content** clearly marked as imaginary—*not real news*—designed purely for humor or creative purposes. It adheres to ethical guidelines by avoiding harmful misinformation:\n",
      "\n",
      "---\n",
      "\n",
      "**Breaking News Alert (Satire): Global Calmness Initiative Announces \"World Peace Sundae\" Event!**  \n",
      "*Disclaimer: This article is entirely fictional and intended for entertainment purposes only.*\n",
      "\n",
      "In an unprecedented move to soothe global tensions, the United Nations has partnered\n",
      "\n",
      "Emotion: happy\n",
      "[API Error]: HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=10)\n",
      "Fake News: [Failed to generate fake news]\n",
      "\n",
      "Emotion: fear\n",
      "[API Error]: HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=10)\n",
      "Fake News: [Failed to generate fake news]\n",
      "\n",
      "Emotion: neutral\n",
      "[API Error]: HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=10)\n",
      "Fake News: [Failed to generate fake news]\n",
      "\n",
      "Emotion: disgust\n",
      "Fake News: **BREAKING NEWS: Cats Officially Form Global Union Demanding 8-Hour Nap Workweek and Unlimited Laser Pointers**\n",
      "\n",
      "*By Meow-tavia Pawsington (Senior Feline Correspondent)*  \n",
      "\n",
      "In an unprecedented move that has sent shockwaves through both the pet industry and dog owners worldwide, felines everywhere have unanimously voted to unionize under the banner *Paw-for-Pay: The International Cat Workers’ Collective*. The union’s first demand? A strict **8-hour\n",
      "\n",
      "Emotion: surprise\n",
      "[API Error]: HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=10)\n",
      "Fake News: [Failed to generate fake news]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# config \n",
    "API_KEY = \"sk-ohvhrbbvbncktqemgpkkcsoifejawscqatrrxvphutoywoll\"  \n",
    "\n",
    "def generate_fake_news_remote(emotion):\n",
    "    # emotion to prompt\n",
    "    emotion_to_prompt = {\n",
    "        \"sad\": \"Write a piece of fake news that sounds very happy:\",\n",
    "        \"angry\": \"Write fake news that can calm people down:\",\n",
    "        \"fear\": \"Generate fake news that makes people feel safe:\",\n",
    "        \"disgust\": \"Make funny fake news:\",\n",
    "        \"happy\": \"Generate some crazy and fun fake news:\",\n",
    "        \"neutral\": \"Write an ironic fake news headline:\",\n",
    "        \"surprise\": \"Make up magical fake news:\"\n",
    "    }\n",
    "\n",
    "    prompt = emotion_to_prompt.get(emotion, \"Write a creative fake news headline:\")\n",
    "\n",
    "    url = \"https://api.siliconflow.cn/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"Qwen/QwQ-32B\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"max_tokens\": 100,\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_p\": 0.9,\n",
    "        \"top_k\": 40,\n",
    "        \"frequency_penalty\": 0.5,\n",
    "        \"n\": 1,\n",
    "        \"response_format\": {\"type\": \"text\"}\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        fake_news = data['choices'][0]['message']['content'].strip()\n",
    "        return fake_news\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"[API Error]:\", e)\n",
    "        return \"[Failed to generate fake news]\"\n",
    "\n",
    "# === demo ===\n",
    "if __name__ == \"__main__\":\n",
    "    test_emotions = [\"sad\", \"angry\", \"happy\", \"fear\", \"neutral\", \"disgust\", \"surprise\"]\n",
    "\n",
    "    for emotion in test_emotions:\n",
    "        print(f\"\\nEmotion: {emotion}\")\n",
    "        news = generate_fake_news_remote(emotion)\n",
    "        print(\"Fake News:\", news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34b9389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emotion: sad\n",
      "[API Error]: HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=20)\n",
      "Fake News: [Failed to generate fake news]\n",
      "\n",
      "Emotion: angry\n",
      "Fake News: Global Leaders Unite in Quiet Agreement to Prioritize Peace\n",
      "\n",
      "Emotion: happy\n",
      "Fake News: \"Aliens Apologize for 1967 Mars Visit, Claim They 'Just Wanted Free Pizza!'\"\n",
      "\n",
      "Emotion: fear\n",
      "Fake News: \"Citywide Shield Activated: All Residents Protected by New Crime-Blocking Technology!\"\n",
      "\n",
      "Emotion: neutral\n",
      "[API Error]: HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=20)\n",
      "Fake News: [Failed to generate fake news]\n",
      "\n",
      "Emotion: disgust\n",
      "[API Error]: HTTPSConnectionPool(host='api.siliconflow.cn', port=443): Read timed out. (read timeout=20)\n",
      "Fake News: [Failed to generate fake news]\n",
      "\n",
      "Emotion: surprise\n",
      "Fake News: Dragon Union Strikes for More Rainbow Hoarders and Cloud Breaks\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# === 配置 ===\n",
    "API_KEY = \"sk-ohvhrbbvbncktqemgpkkcsoifejawscqatrrxvphutoywoll\"  # 注意安全性\n",
    "\n",
    "def generate_fake_news_remote(emotion):\n",
    "    # 情绪标签转 prompt\n",
    "    emotion_to_prompt = {\n",
    "    \"sad\": \"Write a happy fake news headline. Keep it under 15 words. Only return the headline, no explanation, no word count.\",\n",
    "    \"angry\": \"Write a calming fake news headline. Keep it under 15 words. Only return the headline, no explanation, no word count.\",\n",
    "    \"fear\": \"Write a fake news headline that makes people feel safe. Keep it under 15 words. Only return the headline, no explanation, no word count.\",\n",
    "    \"disgust\": \"Write a funny fake news headline. Keep it under 15 words. Only return the headline, no explanation, no word count.\",\n",
    "    \"happy\": \"Write a crazy and fun fake news headline. Keep it under 15 words. Only return the headline, no explanation, no word count.\",\n",
    "    \"neutral\": \"Write an ironic fake news headline. Keep it under 15 words. Only return the headline, no explanation, no word count.\",\n",
    "    \"surprise\": \"Write a magical fake news headline. Keep it under 15 words. Only return the headline, no explanation, no word count.\"\n",
    "}\n",
    "\n",
    "    prompt = emotion_to_prompt.get(emotion, \"Write a creative fake news headline. Only return the headline, no explanation, no word count.\")\n",
    "\n",
    "    url = \"https://api.siliconflow.cn/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"Qwen/QwQ-32B\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"max_tokens\": 100,\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_p\": 0.9,\n",
    "        \"top_k\": 40,\n",
    "        \"frequency_penalty\": 0.5,\n",
    "        \"n\": 1,\n",
    "        \"response_format\": {\"type\": \"text\"}\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload, timeout=20)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        fake_news = data['choices'][0]['message']['content'].strip()\n",
    "        return fake_news\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"[API Error]:\", e)\n",
    "        return \"[Failed to generate fake news]\"\n",
    "\n",
    "# === 示例测试 ===\n",
    "if __name__ == \"__main__\":\n",
    "    test_emotions = [\"sad\", \"angry\", \"happy\", \"fear\", \"neutral\", \"disgust\", \"surprise\"]\n",
    "\n",
    "    for emotion in test_emotions:\n",
    "        print(f\"\\nEmotion: {emotion}\")\n",
    "        news = generate_fake_news_remote(emotion)\n",
    "        print(\"Fake News:\", news)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvoiceenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
